from kokoro import KPipeline
import sounddevice as sd
import numpy as np
# ðŸ‡ºðŸ‡¸ 'a' => American English, ðŸ‡¬ðŸ‡§ 'b' => British English
# ðŸ‡ªðŸ‡¸ 'e' => Spanish es
# ðŸ‡«ðŸ‡· 'f' => French fr-fr
# ðŸ‡®ðŸ‡³ 'h' => Hindi hi
# ðŸ‡®ðŸ‡¹ 'i' => Italian it
# ðŸ‡¯ðŸ‡µ 'j' => Japanese: pip install misaki[ja]
# ðŸ‡§ðŸ‡· 'p' => Brazilian Portuguese pt-br
# ðŸ‡¨ðŸ‡³ 'z' => Mandarin Chinese: pip install misaki[zh]
pipeline = KPipeline(lang_code='z', repo_id='hexgrad/Kokoro-82M') # <= make sure lang_code matches voice, reference above.

def speak(text, voice='af_heart', speed=1):
    generator = pipeline(
        text, voice=voice,
        speed=speed, split_pattern=r'\n+'
    )
    
    audio_chunks = []
    for i, (gs, ps, audio) in enumerate(generator):
        print(f"ç”Ÿæˆè¯­éŸ³æ®µ {i}: {gs}")
        audio_chunks.append(audio)
    
    # åˆå¹¶æ‰€æœ‰éŸ³é¢‘ç‰‡æ®µ
    full_audio = np.concatenate(audio_chunks)
    
    # ç›´æŽ¥æ’­æ”¾éŸ³é¢‘
    print("æ’­æ”¾è¯­éŸ³...")
    sd.play(full_audio, samplerate=24000)
    sd.wait()  # ç­‰å¾…æ’­æ”¾å®Œæˆ
    print("æ’­æ”¾ç»“æŸ")